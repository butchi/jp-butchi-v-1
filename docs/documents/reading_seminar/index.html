<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="../../style.css" type="text/css">
<title>
論文輪講
</title>
<link rel="shortcut icon" href="../../favicon.ico">
</head>

<body>

<h1>論文輪講</h1>
<p>日付のリンクには要約のPDFファイルがリンクされています。</p>
<ul>
  <li><a href="061109.pdf">2006年11月9日</a>
    <ul><li>Yuke Wang and Parhi, K.K.,“A unified adder design,”
IEEE Conference Record of the Thirty-Fifth Asilomar Conference on,
Pacific Grove, CA, USA,
pp. 177-182 Vol.1, November 2001</li></ul>
  </li>
  <li><a href="070529.pdf">2007年5月29日</a>
    <ul><li>A. Oliva, et al.,
“Hybrid Images,”
ACM Transactions on Graphics, ACM Siggraph, 25-3,
pp. 527-530, 2006</li></ul>
  </li>
  <li><a href="070717.pdf">2007年7月17日</a>
    <ul><li>Ahumada et al.,
“Reduction of Display Artifacts by Random Sampling,”
Proceedings of SPIE-The International Soc. for Optical Engineering, vol. 432, 8-83,
pp. 216-221, 1983.</li></ul>
  </li>
  <li><a href="071022.pdf">2007年10月22日</a>
    <ul><li>Akiyoshi Kitaoka,
“Tilt illusions after Oyama (1960): A review,”
Japanese Psychological Research, Volume 49, No. 1,
pp.7-19, 2007</li></ul>
  </li>
  <li><a href="080107.pdf">2008年1月7日</a>
    <ul><li>Terada, T. et al.,
“Nonstationary waveform analysis and synthesis using generalizedharmonic analysis,”
Proceedings of IEEE-SP International Symposium on Time- Frequency and Time-Scale Analysis TFSA-94,
pp.429-432, 1994</li></ul>
  </li>
  <li><a href="080521.pdf">2008年5月21日</a>
    <ul><li>Yu Nishibori, Toshio Iwai,
“TENORI-ON”,
Proceedings of 6th International Conference on New Interfaces for Musical Expression, Paris, France,
pp.172-175, 2006.</li></ul>
  </li>
  <li><a href="080618.pdf">2008年6月18日</a>
    <ul><li>G. Levin and Z. Lieberman, “Sounds from Shapes: Audiovisual Performance with Hand Silhouette Contours
in The Manual Input Sessions,”
Proceedings of NIME '05, Vancouver, BC, Canada. May pp.26-28, 2005.</li></ul>
  </li>
  <li><a href="081022.pdf">2008年10月22日「空間情報を用いた音声生成に関する研究動向」</a>（<a href="081022.ppt">補足資料(.ppt)</a>）
    <ul>
      <li>江渡浩一郎, “アート・エンターテインメントに
おける音インタフェース,” 情報処理学会研究報
告. SLP, 音声言語情報処理, Vol. 2004, No. 74,
pp. 53-58, 2004.</li>
      <li>H. Solís, “Improvisatory music and painting
interface,” Masters thesis, Massachusetts Institute
of Technology, 2004.</li>
      <li><a href="http://www.korg.co.jp/Product/Dance/
kaossilator/">KORG “KAOSSILATOR”</a></li>
      <li>Yu Nishibori, Toshio Iwai, “TENORI-ON”,
Proceedings of NIME, pp.172-175, 2006.</li>
      <li><a href="http://www.bastwood.com/aphex.php">bastwood.com “The Aphex Face”</a></li>
      <li><a href="http://www.musanim.com/">S. Malinowski “The Music Animation Machine”</a></li>
      <li>岩淵勇樹, 秋田純一, 北川章夫, “閉曲線図形に基づいた音色生成方法の検討,”
エンタテインメントコンピューティング2008論文集, pp.143-146, 2008</li>
      <li>港隆史, 関戸智史, 石黒浩, 河原英紀,
“全方位視覚の特性を利用した画像から音信号への変換,”
日本ロボット学会第20 回学術講演会予稿集, 2002.</li>
    </ul>
  </li>
  <li><a href="100205.pdf">2010年2月5日</a>
    <ul><li>K. Ogawa and Y. Kuhara, “Life Game Orchestra as an Interactive Music Composition System Translating Cellular Patterns of Automata into Musical Scales,”
The 9th International Conference on New Interfaces for Musical Expression,
pp.50-51, Pittsburgh, Pennsylvania, USA, 2009.</li></ul>
  </li>
  <li><a href="100615.pdf">2010年6月15日</a>
    <ul><li>Masato Miyoshi, Yutaka Kaneda, “Inverse Filtering of Room Acoustics,”
IEEE Transactions on Acoustics, Speech and Signal Processing, Vol. 36, No. 2,
pp.145-152, 1988</li></ul>
  </li>
  <li><a href="100803.pdf">2010年8月3日</a>
    <ul>
      <li>中野倫靖，緒方淳，後藤真孝，平賀譲：
口ドラム認識手法とそのドラム譜入力システムへの応用，
情報処理学会論文誌Vol. 48 No. 1
pp. 386-397，2007</li>
      <li>後藤真孝，平田圭二：
音楽情報処理の最近の研究，
日本音響学会誌Vol. 60，No. 11
pp. 675-681，2004</li>
    </ul>
  </li>
  <li><a href="101116.pdf">2010年11月16日</a>
    <ul><li>K. Nishimoto, T. Maekawa, Y. Tada, K. Mase and R. Nakatsu,
“Networked wearable musical instruments will bring a new musical culture.”
Proc. ISWC 2001, pp. 55-62, 2001.</li></ul>
  </li>
  <li><a href="110201.pdf">2011年2月1日</a>
    <ul>
      <li>安藤大地，馬場哲晃：
“マルチタッチディスプレイを利用した電子擦弦楽器とエフェクトコントローラ”，
インタラクション2010論文集</li>
      <li>野尻抱介：“「あの楽器」―いまここ。”，
Make: Technology on Your Time, Vol.7, pp.82-85，2009.</li>
      <li>野田陽：“LED パネルと探知センサーを使った「あの楽器」春日モデル”，
Make: Technology on Your Time, Vol.7, pp.90-93，2009.</li>
      <li>笹尾和宏：“小型プロジェクターでマルチタッチを実現した「あの楽器」笹尾モデル”，
Make: Technology on Your Time, Vol. 7, pp. 86-89，2009.</li>
      <li>小倉敏彦：“GainerとProcessingでギター風「あの楽器」”，Make:
Technology on Your Time, Vol. 7, pp. 86-89，2009.</li>

    </ul>
  </li>
  <li><a href="110607.pdf">2011年6月7日</a>
    <ul><li>R. Boulanger, P. Smaragdis, and J. Ffitch,
“Scanned Synthesis: An introduction and demonstration of a new synthesis and signal processing technique,” Proceedings of the 2000 International Computer Music Conference, pp. 372-375, 2000.</li></ul>
  </li>

  <li><a href="110726.pdf">2011年7月26日</a>
    <ul><li>S. Park, S. Kim, S. Lee, and W. S. Yeo,
“Composition with path: Musical sonification of geo-referenced data with online map interface,”
Proceedings of the International Computer Music Conference (ICMC), New York, 2010.</li></ul>
  </li>


  <li><a href="111109.pdf">2011年11月9日</a>
    <ul><li>W. S. Yeo, and J. Berger,
“Application of raster scanning method to image sonification, sound visualization, sound analysis and synthesis,”
Proc of the 9th Int. Conference on Digital Audio Effects. Montreal, Canada, 2006</li></ul>
  </li>

  <li><a href="120111.pptx">2012年1月11日</a>
    <ul><li>T. Hermann,
    “Taxonomy and definitions for sonification and auditory display,”
    Proc. of the 14th ICAD, Paris, 2008</li></ul>
  </li>

<!--
  <li><a href=""></a>
    <ul><li></li></ul>
  </li>
-->
</ul>

<br>
<a href="../../">Home</a>
<!--Google Analystics--><script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-2779957-3");
pageTracker._trackPageview();
} catch(err) {}</script><!--/Google Analystics-->

</body>
</html>
